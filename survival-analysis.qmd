---
format:
  html:
    number-depth: 3
    css: summary-format.css
---
# Survival Analysis and Censored Data

## General concepts

In this models the outcome variable is the **time until an event occurs** or any other numeric variable have been **censored** by any limitation during data collection.

- **Survival, failure or event time** $T$: Represents the time at which the event of interest occurs. For instance, the time at which the *patient dies* or the *customer cancels his or her subscription*.
- **Censoring time** $C$: Represents the time at which censoring occurs. For example, the time at which the patient *drops out of the study* or the *study ends*.

As result our target variable is the result of:

$$
Y = \min(T, C)
$$

To know how to interpret the results we will need an indicator:

$$
\delta = 
 \begin{cases}
   1 & \quad \text{if } T \leq C \\
   0 & \quad \text{if } T > C
 \end{cases}
$$

As result when $\delta = 1$ we observe the true survival time, and when $\delta = 0$ if we observe the censoring time.In the next example, we just could observe the event for patients 1 and 3 before ending the study.

![](img/55-censored-survival-example.png){fig-align="center"}

### Assumptions

In order to analyze survival data, we need to determine whether the following assumptions are reasonable:

- The **event time** $T$ **is independent of the censoring time** $C$. For example, *patients drop out of the cancer study early because they are very sick*, that would **overestimate** the true average survival time. We can check this assumption by exploring the ***reasons related to dropouts***.

- The **predictors are independent of the censoring event** $\delta = 0$. For example, if in our study *very sick males are more likely to drop out of the study than very sick females*, that would drive the **wrong conclusion** that males survive longer than females.

### Censoring types

1. **Right censoring**: It occurs when $T \geq Y$, i.e. the true event time $T$ is at least as large as the observed time $Y$.
2. **Left censoring**: It occurs when $T \leq Y$, i.e. the true event time $T$ is less than or equal to the observed time $Y$.
3. **Interval censoring**: It refers to the setting in which we do not know the exact event time, but we know that it falls in some interval.

*Right censoring will be the main focus of this chapter.*

## Kaplan-Meier Survival Curve

The **survival curve (function)** is defined as the probability that the *event time* $T$ happens later than a time $t$. As result, *the larger the value of *$S(t)$*, the less likely that the event would take place before time* $t$. 

$$
S(t) = \Pr(T > t)
$$

To explain how complicated can be to estimate $S(20) = \Pr(T>20)$ when our target variable is a mix of event and censored times we will use the `ISLR2::BrainCancer` table as a example.

```{r}
pillar::glimpse(ISLR2::BrainCancer)

data.table::as.data.table(ISLR2::BrainCancer) |>
  (\(DT) DT[, .N,
            keyby = .(alive_20_months = time > 20,
                      event_time = status)])()
  
```

- Taking the total of patients who were alive after 20 months ($36+12=48$) over the total number of patients ($48/88 \approx 55\%$) would be a mistake as we cannot assume that $T < 20$ for $17$ censored patients.

- Omitting the $17$ censored patients might sound as solution but that would **under estimate** the probability as a patient who was censored at $t = 19.9$ likely would have survived past $t = 20$, and would be better to take a advantage of that censored time.

To overcome this challenge let's define:

- $d_1 < d_2 < \dots < d_K$: The $K$ unique death times among the non-censored patients.
- $q_k$: The number of patients who died at time $d_k$.
- $r_k$: The number of patients alive and in the study just before $d_k$, *at risk patients*.
- $\widehat{\Pr}(T > d_j|T > d_{j-1}) = (r_j - q_j) / r_j$: It estimates the fraction of the risk set at time $d_j$ who survived past time $d_j$.

*And based on the law of total probability*

$$
\begin{split}
\Pr(T > d_k) = & \Pr(T > d_k|T > d_{k-1}) \Pr(T > d_{k-1}) + \\
               & \Pr(T > d_k|T \leq d_{k-1}) \Pr(T \leq d_{k-1})
\end{split}
$$

But as it is impossible for a patient to survive past time $d_k$ if he or she did not survive until an earlier time $d_{kâˆ’1}$, we know that $\Pr(T > d_k|T \leq d_{k-1}) = 0$ and we can simplify the function and found out that this a recurrent function.

$$
\begin{split}
\Pr(T > d_k) = & \Pr(T > d_k|T > d_{k-1}) \Pr(T > d_{k-1}) \\
S(d_k) = & \Pr(T > d_k|T > d_{k-1}) \times \dots \times \Pr(T > d_2|T > d_1) \Pr(T > d_1) \\
\hat{S}(d_k) = & \prod_{j=1}^k \left( \frac{r_j - q_j}{r_j} \right)
\end{split}
$$

As we can see the the example below, the **Kaplan-Meier survival curve** has a step-like shape as we assume that $\hat{S}(t) = \hat{S}(d_k)$ when $d_k < t < d_{k+1}$.

![](img/56-Kaplan-Meier-survival-curve.png){fig-align="center"}

*Based on this new function we can say that the probability of survival past 20 months is* $71\%$.


## Log-Rank Test

If we want to explore whether the sex is an important factor to impact the *survival curve* we can create a plot comparing the curve of each sex.

![](img/57-survival-curve-male-female.png){fig-align="center"}

Females seem to fare a little better up to about 50 months, but then the two curves both level off to about 50%. To take a better decision we need to confirm if this difference was produced by chance or if it was statistical significant.

As our target variable `time` mixes event and censoring times we need to use a particular statistical test known as **log-rank test**, **Mantel-Haenszel test** or **Cochran-Mantel-Haenszel test**. In this test we need to split some the variables used in the Kaplan-Meier survival curve.

$$
\begin{split}
r_{1k} + r_{2k} & = r_k \\
q_{1k} + q_{2k} & = q_k
\end{split}
$$

In order to test $H_0 : \text{E}(X) = 0$ for some random variable $X$, one approach is to construct a test statistic of the form

$$
W = \frac{X - \text{E}(X)}{\sqrt{\text{Var}(X)}}
$$

Where:

$$
\begin{split}
X & = \sum_{k=1}^K q_{1k} \\
\text{E}(q_{1k}) & = \frac{r_{1k}}{r_k} q_k \\
\text{Var}\left( X \right) \approx \sum_{k=1}^K \text{Var} (q_{1k}) & = \sum_{k=1}^K \frac{q_k(r_{1k}/r_k) (1-r_{1k}/r_k) (r_k-q_k)}{r_k-1}
\end{split}
$$

As result

$$
\begin{split}
W & = \frac{\sum_{k=1}^K(q_{1k}-\text{E}(q_{1k}))}
           {\sqrt{\sum_{k=1}^K \text{Var} (q_{1k})}} \\
& = \frac{\sum_{k=1}^K(q_{1k}- \frac{r_{1k}}{r_k} q_k)}
         {\sqrt{\sum_{k=1}^K \frac{q_k(r_{1k}/r_k) (1-r_{1k}/r_k) (r_k-q_k)}{r_k-1}}}
\end{split}
$$

When the **sample size is large**, the log-rank test statistic $W$ has approximately a **standard normal distribution** and can be used to compute a **p-value** for the null hypothesis that there is no difference between the survival curves in the two groups. 

For the `ISLR2::BrainCancer`the **p-value is 0.2** using the theoretical null distribution. Thus, **we cannot reject the null hypothesis** of no difference in survival curves between females and males.

## Regression Models With a Survival Response

Fitting a linear regression to a censored data can be challenging as we want to predict $T$ rather than $Y$ and to overcome this difficulty need to use *a sequential construction*.

### Hazard Function

#### Definition

The **hazard function** also known as *hazard rate* or *force of mortality* is useful to estimate the **risk of an event** and measures the  instantaneous rate (*conditional probability/unit of time*) at which events occur given that the event has not yet occurred for the subjects under study.

$$
h(t) = \lim_{\Delta t \rightarrow 0} \frac{\Pr(t < T \leq t + \Delta t| T > t)}{\Delta t}
$$

Where:

- $T$: It is the (unobserved) survival time.
- $\Delta t$: It's an extremely tiny number.

It has a close relational with the **probability density function of** $T$ which shows how *common* or *rare* is any particular $T$ value is likely to be:

$$
f(t) = \lim_{\Delta t \rightarrow 0} \frac{\Pr(t < T \leq t + \Delta t)}{\Delta t}
$$

Using the conditional probability definition we can find how the *hazard function* connect the *probability density function* and the *survival function*.

$$
\begin{split}
h(t) & = \lim_{\Delta t \rightarrow 0} \frac{\Pr((t < T \leq t + \Delta t) \cap (T > t)) / \Pr(T > t)}{\Delta t} \\
h(t) & = \lim_{\Delta t \rightarrow 0} \frac{\Pr(t < T \leq t + \Delta t) / \Delta t }{\Pr(T > t)}  \\
h(t) & = \frac{f(t)}{S(t)}
\end{split}
$$

Let's see a simulated example:

```{r hazard-rate-simulated-plot}
#| code-fold: true
# Setup
library(ggplot2)
mu <- 5
sigma <- 1
t <- 3:6

# Create a data frame of values around the mean
df <- data.frame(x = seq(mu-4*sigma, mu+4*sigma, length=1000))
df$Density <- dnorm(df$x, mean=mu, sd=sigma)
df$S <- pnorm(df$x, mean=mu, sd=sigma, lower.tail = FALSE)

# Define hazard points to estimate
annotations <-data.frame(
  t,
  density = dnorm(t, mean=mu, sd=sigma) |> round(2),
  survival = pnorm(t, mean=mu, sd=sigma, lower.tail = FALSE) |> round(2),
  hazard = 
    (dnorm(t, mean=mu, sd=sigma) /
       pnorm(t, mean=mu, sd=sigma, lower.tail = FALSE)) |>
    round(2)
)

annotations$label <- paste0(
  annotations$density," / ",
  annotations$survival," = ", 
  annotations$hazard
)

# Plot the normal distribution
ggplot(df, aes(x=x, y=Density)) + 
  geom_blank(aes(y = Density*1.2)) +
  geom_line() +
  geom_area(data= subset(df, x > max(t)),
            fill="blue", 
            alpha = 0.4) +
  geom_point(data = annotations,
             aes(x = t, y = density),
             size = 3) +
  geom_text(data = annotations,
            aes(x = t, y = density, label = label),
            vjust = -1,
            fontface = "bold",
            size = 4) +
  labs(x="x", 
       y="Probability Density",
       title = "Hazard rate = f(t) / S(t), where f(t) is represented by a normal distribution") +
  scale_x_continuous(breaks = scales::breaks_width(1)) +
  theme_classic()+
  theme(plot.title = element_text(face = "bold", 
                                  margin = margin(b = 0.5, unit = "cm")))
```

#### Modeling the survival time

To use the hazard function to **model the survival time** as a function of the **covariates** (predictors), we can assume the next form for the hazard function to assure positive results:

$$
h(t|x_i) = \exp \left( \beta_0 + \sum_{j=1}^p \beta_j x_{ij} \right)
$$

Based on $h(t|x_i)$ we can calculate $S(t|x_i)$ and maximize the next likelihood function to estimate the parameters $\beta$ assuming that the $n$ **observations are independent**

$$
L = \prod_{i=1}^n h(y_i)^{\delta_i} S(y_i)
$$

- When the $i$th observation is **not censored** ($\delta = 1$) the likelihood is the **probability of dying** $f(y_i)$ in a tiny interval around time $y_i$.
- When the $i$th observation is **censored**($\delta = 0$) the likelihood is the **probability of surviving** $S(y_i)$ at least until time $y_i$.

### Proportional Hazards

#### Assumptions

#### Coxâ€™s Proportional Hazards Model

#### Connection With The Log-Rank Test

### Examples

#### Brain Cancer Data

#### Publication Data






